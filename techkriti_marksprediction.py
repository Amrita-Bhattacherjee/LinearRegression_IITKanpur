# -*- coding: utf-8 -*-
"""Techkriti_MarksPrediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_VROyeLHngeIxUhQfaO2L2DsXybFU3PQ

#Loading and Visualizing the Data
The following code predicts marks obtained by a student when the number of hours studied by the student is given as an input. This is a simple example of Linear Regression.
"""

# Commented out IPython magic to ensure Python compatibility.
#Importing the required libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
# %matplotlib inline

#Loading the data from a remote link'
url="http://bit.ly/w-data"
s_data=pd.read_csv(url)
print("Data imported successfully")

s_data.head(10)

"""Now that the data is loaded, we plot the data on a 2-D graph to visualize it."""

#Plotting the distribution of scores against the study hours
s_data.plot(x='Hours',y='Scores',style='o')
plt.title('Hours vs Marks out of 100')
plt.xlabel('Hours studied')
plt.ylabel('Percentage Score')
plt.show()

"""Note that the graph indicates a positive linear relationshhip.

#Preparing the Data
The next step is to divide the data into 'attributes' (input) and 'labels'(output).
"""

X=s_data.iloc[:,:-1].values
y=s_data.iloc[:,1].values

"""After dividing the data into attributes and labels, we divide the entire dataset into training set and test set.

We will do this by using Scikit-Learn's built-in **train_test_split()** method.
"""

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=0)
#20% of the dataset is taken as the test set

"""#Training the Algorithm
We have split the data into training and testing sets. Now, we have to train the model.
"""

from sklearn.linear_model import LinearRegression
regressor = LinearRegression()
regressor.fit(X_train,y_train)

print("Training complete.")

#Plotting the fitted line on our entire dataset
line=regressor.coef_*X+regressor.intercept_

plt.scatter(X,y)
plt.plot(X,line)
plt.show()

"""#Making Predictions
The model is trained and a regression equation is obtained which gives us the line of best fit. Now, we have to use this regression equation to predict the value of y for unseen data (test set).
"""

y_pred=regressor.predict(X_test)

#Comparing actual vs predicted values
df = pd.DataFrame({'Actual':y_test, 'Predicted':y_pred})
df

"""The test data has been predicted and displayed. Let us now check for any random study hour which is neither in the test nor in the training set."""

score_pred = np.array([9.25, 0.6, 3.5, 5.8])
score_pred = score_pred.reshape(-1,1)
predict = regressor.predict(score_pred)
score_pred=score_pred.reshape(-1)

df_new = pd.DataFrame({'Hours':score_pred, 'Marks Predicted':predict})
df_new

"""#Evaluating the Model
The final step is to evaluate the performance of the algorithm. This step is particularly important to compare different algorithms on the same dataset, in order to select the most suitable algorithm.

For simplicity, let us choose the MSE (mean squared error). There are many such metrics.
"""

from sklearn import metrics
mse=metrics.mean_absolute_error(y_test,y_pred)
print('Mean Absolute Error is',mse)